{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "path = '../raw'\n",
    "path_lojas_atuais = f'{path}/lojas_atuais.csv'\n",
    "path_faturamento_lojas_atuais = f'{path}/faturamento_lojas_atuais.csv'\n",
    "path_cenarios_expansao = f'{path}/cenarios_expansao.csv'\n",
    "\n",
    "lojas = pd.read_csv(path_lojas_atuais)\n",
    "faturamento = pd.read_csv(path_faturamento_lojas_atuais)\n",
    "expansao = pd.read_csv(path_cenarios_expansao)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrumando o dataset para ficar do jeito que vamos treinar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_ibge = 'tabelas_ibge_uteis/tabela392_csv.csv'\n",
    "\n",
    "ibge = pd.read_csv(path_ibge, sep=';', encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ibge_values = ibge['ï»¿Areas'].values\n",
    "#ibge.drop(['ï»¿Areas'], axis=1, inplace=True)\n",
    "#ibge['Areas'] = pd.Series(ibge_values)\n",
    "ibge.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibge.columns\n",
    "ibge = ibge.rename(columns={'Column5': 'renda_media', 'Column11': 'cod_ap'})\n",
    "ibge.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibge = ibge[['cod_ap', 'renda_media']]\n",
    "ibge.head()\n",
    "ibge.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lojas.sample(30)\n",
    "\n",
    "# IMPORTANTE -> FEATURES 13 a 15 ou todas estao presentes ou nenhuma esta presente -> tranformar em feature binaria posteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lojas.isnull().sum()\n",
    "print(lojas.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mudar os types:\n",
    "\n",
    "# observacao feat 12 e binaria na vdd mas vamos deixar assim, pq\n",
    "# ainda teremos que lidar com missing values, entao ter 3 categorias\n",
    "# na vdd\n",
    "lojas['cod_loja'] = lojas['cod_loja'].astype(str)\n",
    "lojas['cod_ap'] = lojas['cod_ap'].astype(str)\n",
    "lojas['cod_municipio'] = lojas['cod_municipio'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lojas.shape)\n",
    "print(lojas.info())\n",
    "print(lojas.duplicated().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  lojas onde foi inputado -1 (nao se conhece dados geograficos)\n",
    "lojas[lojas['cod_ap'] == '-1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faturamento.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(faturamento.shape)\n",
    "print(faturamento.info())\n",
    "print(faturamento.duplicated().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expansao.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(expansao.shape)\n",
    "print(expansao.info())\n",
    "print(expansao.duplicated().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faturamento['cod_loja'].nunique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lojas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(expansao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faturamento.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faturamento.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faturamento.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colocar as categorias para cada mes\n",
    "\n",
    "cat_concat_list = []\n",
    "loja_ano_mes_cont_list = []\n",
    "i = 0\n",
    "for ((cod_loja, ano, mes), gp) in faturamento.groupby(['cod_loja', 'ano', 'mes']):\n",
    "    month_categories = pd.Series(gp['qtde'].values, index=gp['categoria'].values).to_dict()\n",
    "    cat_df = pd.DataFrame(month_categories, index=[i])\n",
    "    cat_concat_list.append(cat_df)\n",
    "    loja_ano_mes_cont_list.append({'cod_loja':cod_loja, 'ano':ano, 'mes':mes})\n",
    "    i += 1 \n",
    "cat_full = pd.concat([*cat_concat_list])\n",
    "loja_ano_mes_cont_full = pd.DataFrame(loja_ano_mes_cont_list)\n",
    "loja_ano_mes_cont_full.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loja_ano_mes_cont_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "faturamento = faturamento.groupby(['cod_loja', 'ano', 'mes'])[['qtde', 'receita']].sum().reset_index(drop = True)\n",
    "faturamento.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faturamento = pd.concat([loja_ano_mes_cont_full, faturamento, cat_full], axis=1)\n",
    "faturamento.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faturamento.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faturamento.to_csv('../final/estrabico.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todas as combinacoes possiveis de loja, ano, mes\n",
    "# garantir que nao vai faltar nada\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "loja_unique = faturamento['cod_loja'].unique()\n",
    "ano_unique = faturamento['ano'].unique()\n",
    "mes_unique = faturamento['mes'].unique()\n",
    "\n",
    "all_combinations = np.vstack(list(product(loja_unique, ano_unique, mes_unique)))\n",
    "\n",
    "combinations_faturamento = pd.DataFrame(all_combinations, columns=['cod_loja', 'ano', 'mes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations_faturamento = combinations_faturamento.sort_values(by=['cod_loja', 'ano', 'mes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faturamento = pd.merge(faturamento, combinations_faturamento, on=['cod_loja', 'ano', 'mes'], how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faturamento.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faturamento.loc[faturamento['ano'] == 2016, 'mes_cont'] = faturamento.loc[faturamento['ano'] == 2016, 'mes']\n",
    "faturamento.loc[faturamento['ano'] == 2017, 'mes_cont'] = 12 + faturamento.loc[faturamento['ano'] == 2017, 'mes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(faturamento['CATEG_08'].max())\n",
    "print(faturamento['CATEG_08'].mean())\n",
    "print(faturamento['CATEG_07'].max())\n",
    "print(faturamento['CATEG_07'].mean())\n",
    "print(faturamento['CATEG_06'].max())\n",
    "print(faturamento['CATEG_06'].mean())\n",
    "print(faturamento['CATEG_05'].max())\n",
    "print(faturamento['CATEG_05'].mean())\n",
    "print(faturamento['CATEG_04'].max())\n",
    "print(faturamento['CATEG_04'].mean())\n",
    "print(faturamento['CATEG_03'].max())\n",
    "print(faturamento['CATEG_03'].mean())\n",
    "print(faturamento['CATEG_02'].max())\n",
    "print(faturamento['CATEG_02'].mean())\n",
    "print(faturamento['CATEG_01'].max())\n",
    "print(faturamento['CATEG_01'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faturamento['cod_loja'] = faturamento['cod_loja'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faturamento = pd.merge(faturamento, lojas, on='cod_loja', how='inner')\n",
    "faturamento.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faturamento.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faturamento.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faturamento['cod_ap'] = faturamento['cod_ap'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faturamento = pd.merge(faturamento, ibge, on='cod_ap', how='left')\n",
    "faturamento.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faturamento.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faturamento.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faturamento.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faturamento['cod_ap'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faturamento['cod_municipio'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faturamento['renda_media'] = faturamento['renda_media'].astype(str).str.translate({32:None, 44:46}).astype(float)\n",
    "faturamento['ano'] = faturamento['ano'].astype(str)\n",
    "faturamento['mes'] = faturamento['mes'].astype(str)\n",
    "faturamento.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estado\n",
    "\n",
    "cod_estado = faturamento['cod_municipio'].astype('str').str[:2]\n",
    "cod_estado = cod_estado.replace({'11' : 'RO', '12' : 'AC', '13' : 'AM', '14' : 'RR', '15' : 'PA',\n",
    "                                 '16' : 'AP', '17' : 'TO', '21' : 'MA', '22' : 'PI', '23' : 'CE',\n",
    "                                 '24' : 'RN', '25' : 'PB', '26' : 'PE', '27' : 'AL', '28' : 'SE',\n",
    "                                 '29' : 'BA', '31' : 'MG', '32' : 'ES', '33' : 'RJ', '35' : 'SP',\n",
    "                                 '41' : 'PR', '42' : 'SC', '43' : 'RS', '50' : 'MS', '51' : 'MT',\n",
    "                                 '52' : 'GO', '53' : 'DF'})\n",
    "faturamento['estado'] =  cod_estado\n",
    "\n",
    "# regiao \n",
    "\n",
    "cod_regiao = faturamento['estado'].astype('str').str[:2]\n",
    "cod_regiao = cod_regiao.replace({'RO' : 'NT', 'AC' : 'NT', 'AM' : 'NT', 'RR' : 'NT', 'PA' : 'NT',\n",
    "                                 'AP' : 'NT', 'TO' : 'NT', 'MA' : 'NE', 'PI' : 'NE', 'CE' : 'NE',\n",
    "                                 'RN' : 'NE', 'PB' : 'NE', 'PE' : 'NE', 'AL' : 'NE', 'SE' : 'NE',\n",
    "                                 'BA' : 'NE', 'MG' : 'SD', 'ES' : 'SD', 'RJ' : 'SD', 'PR' : 'SU',\n",
    "                                 'SC' : 'SU', 'RS' : 'SU', 'MS' : 'CO', 'MT' : 'CO', 'MS' : 'CO',\n",
    "                                 'GO' : 'CO', 'DF' : 'CO'})\n",
    "faturamento['regiao'] =  cod_regiao\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faturamento.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faturamento.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "localidades = pd.read_csv('localidades.csv', sep=';', encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "localidades.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "localidades.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "localidades = localidades.rename(columns={'CD_GEOCODSD': 'cod_municipio', 'LONG': 'long', 'LAT': 'lat' })\n",
    "localidades = localidades.loc[:, ['cod_municipio', 'long', 'lat']]\n",
    "# cod muicipio vem com trailing zeros\n",
    "localidades['cod_municipio'] = localidades['cod_municipio'].astype(str).str[:7]\n",
    "localidades['lat'] = localidades['lat'].astype(str).str.translate({32:None, 44:46}).astype(float)\n",
    "localidades['long'] = localidades['long'].astype(str).str.translate({32:None, 44:46}).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "localidades.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pegando a media de latitude e longitude das areas como aproximacao do muncipiio\n",
    "localidades = localidades.groupby('cod_municipio').mean()\n",
    "localidades.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latitude e longitude por municipio\n",
    "faturamento = pd.merge(faturamento, localidades, on='cod_municipio', how='left')\n",
    "faturamento.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_missing = faturamento.isnull().sum() * 100 / len(faturamento)\n",
    "missing_value_df = pd.DataFrame({'column_name': faturamento.columns,\n",
    "                                 'percent_missing': percent_missing}).reset_index(drop=True)\n",
    "missing_value_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# observacao importante : tem -1  em cod_ap, cod_municipio, regiao e estado. Por isso que aparece como se nao tivesse nenhum \n",
    "# missing value mas na vdd tem. Para substutui os missing values, samplear de uma gaussian fitada nos dados existentes uma boa?\n",
    "\n",
    "# porem o fato de nao termos os dados diz algo a mais sobre essas lojas? tem relacao com a receita?\n",
    "faturamento[faturamento['cod_ap'] == '-1'].sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA \n",
    "    # target variable and aproximate target variable (que a gente nao vai ter para submissao) \n",
    "    # pair anlysis\n",
    "    # corr matrices\n",
    "    # multicolinearity\n",
    "    # etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Obsevacoes:\n",
    "        \n",
    "        # Check Correlations and Multicolinearity in data\n",
    "             # no  test set só teremos cod_loja, mes_cont, cod_ap, cod_municipio, renda_media, lat, long, num_lojas_regiao\n",
    "             # sabemos que temos colinearidade forte entre cod_ap e renda_media, e de cod_municipio com lat e long \n",
    "             # tambem poderemos ter colinearidade forte de cod_loja com as features da loja\n",
    "             # ferramentas: - teste VIF de multicolinearidade; chi-square test for independece, anova, pearson correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faturamento['cod_loja'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(faturamento.info())\n",
    "print(faturamento.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! parei aqui\n",
    "# tem 167 lojas que tem meses faltando no ano\n",
    "check_months = faturamento.groupby('cod_loja')['mes_cont'].nunique()\n",
    "# tem que dar zero\n",
    "print(len(check_months[check_months!=24]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faturamento['cod_loja'] = faturamento['cod_loja'].astype(int)\n",
    "faturamento['ano'] = faturamento['ano'].astype(int)\n",
    "faturamento['mes'] = faturamento['mes'].astype(int)\n",
    "faturamento = faturamento.sort_values(by=['cod_loja', 'ano', 'mes'])\n",
    "faturamento['cod_loja'] = faturamento['cod_loja'].astype(str)\n",
    "faturamento['ano'] = faturamento['ano'].astype(str)\n",
    "faturamento['mes'] = faturamento['mes'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faturamento[216:240]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets por loja \n",
    "# !!! tem lojas com meses faltando !!!\n",
    "\n",
    "faturamentos_lojas = [ faturamento[24*i:24*i+24] for i in range(3131)]\n",
    "\n",
    "print(faturamentos_lojas[9]['mes'])\n",
    "\n",
    "#pegando lojas aleatorias\n",
    "for i in range(5):\n",
    "    rand = np.random.randint(0, 3131)\n",
    "    #plot something\n",
    "    fig, ax = plt.subplots()\n",
    "    dataframe_loja = faturamentos_lojas[rand]\n",
    "    #print(dataframe_loja)\n",
    "    dataframe_loja['receita'][:12].reset_index(drop=True).plot(kind='line', ax=ax)\n",
    "    dataframe_loja['receita'][12:].reset_index(drop=True).plot(kind='line', ax=ax)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analise global , media da receita das lojas ao longo do tempo\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "faturamanto_receita_media = faturamento.groupby('mes_cont')['receita'].mean().plot(kind='line', ax=ax)\n",
    "plt.show()\n",
    "\n",
    "# diferenca media entre os anos\n",
    "faturamanto_receita_media_2016 = faturamanto_receita_media[:13]\n",
    "faturamanto_receita_media_2017 = faturamanto_receita_media[13:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Lojas com geo desconhecido (-1) - média geral: {}'.format(faturamento[faturamento['cod_ap'] == '-1']['receita'].mean()))\n",
    "print('Lojas com geo desconhecido - std geral: {}'.format(faturamento[faturamento['cod_ap'] == '-1']['receita'].std()))\n",
    "print('----------------')\n",
    "print('Lojas com geo conhecido - média geral: {}'.format(faturamento[faturamento['cod_ap'] != '-1']['receita'].mean()))\n",
    "print('Lojas com geo conhecido - std geral: {}'.format(faturamento[faturamento['cod_ap'] != '-1']['receita'].std()))\n",
    "\n",
    "# no conjunto de lojas -1 a media eh menor(mas parece bem pouco) e a variancia eh maior (talvez seja reelvante aqui)\n",
    "\n",
    "# plotar as distribuicoes das receitas\n",
    "receitas_geo_desconhecido = faturamento[faturamento['cod_ap'] == '-1']['receita']                                      \n",
    "receitas_geo_conhecido = faturamento[faturamento['cod_ap'] != '-1']['receita']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rows which features from 13 to 18 are NaN\n",
    "\n",
    "print('Lojas com NaN - média geral: {}'.format(faturamento[faturamento['feature_14'] != faturamento['feature_14']]['receita'].mean()))\n",
    "print('Lojas com NaN - std geral: {}'.format(faturamento[faturamento['feature_14'] != faturamento['feature_14']]['receita'].std()))\n",
    "print('----------------')\n",
    "print('Lojas com features -  média geral:{}'.format(faturamento[faturamento['feature_14'] == faturamento['feature_14']]['receita'].mean()))\n",
    "print('Lojas com features -  std geral:{}'.format(faturamento[faturamento['feature_14'] == faturamento['feature_14']]['receita'].std()))\n",
    "\n",
    "#IMPORTANTE: Lojas que NaN nas features 13-18 tem receita mt menor!\n",
    "# lojas quiosque talvez ?\n",
    "\n",
    "# plotar as dsitribuicoes das receitas\n",
    "# ver se as features estao influenciado a receita em faturamento_features_conhecidas (plotar)\n",
    "\n",
    "receitas_features_NaN = faturamento[faturamento['feature_14'] != faturamento['feature_14']]['receita']\n",
    "receitas_features_conhecidas = faturamento[faturamento['feature_14'] == faturamento['feature_14']]['receita']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# influencia do numero de lojas na regiao\n",
    "receita_regiao = faturamento.groupby('cod_ap').aggregate({'cod_loja': 'count','receita': 'mean'})\n",
    "receita_regiao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faturamento.to_csv('../processed/estrabico.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target-value - receita\n",
    "# Tem duas temporadas mesmo de receita? uma no meio do ano e outra no final? \n",
    "    #-> daria pra colocar feature binaria pros meses do meio do ano\n",
    "# o ano eh importante?\n",
    "# testar sazonalidade de trimestre \n",
    "# sazonalidade da receita pode ser diferente para cada loja/regiao/categoria?\n",
    "#a avliar isso para a media de todas as lojas, media de todas as lojas por regiao\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lojas grandes e lojas normais? Existem grupos de lojas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ver o comportamento de tipos de categorias presentes em cada mês "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# como as categorias diferem em vendas e receita, e preço consequentemente?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# como preço da categorias varia durante o tempo?  Inflação importante? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agr sobre as features das lojas\n",
    "\n",
    "# features 7 e 8 bem parecidas?\n",
    "# feature 9 parece ter dois grupos definidos, um de valores maiores e outro de valores menores , ver isso aí\n",
    "# se features 13-18 sao influentes (pq sempre que elas aparecem, aparecem juntas), e um binario nao eh suficiente:\n",
    "    # feature 15 parece ter valores discretos bem definidos, relacionada a fração de alguma coisa, tipo x/10 * 1000 -> substituir por números de 1 a 10? Dividir em grupos maiores?\n",
    "    # fature 16 parece ser binária, 500 ou 1000, tratar como binária? ou 1 e 2 ?\n",
    "    # features 13, 15, 16 tem os valores máximos = moda = 1000 , colocar features binárias para a presença de max?\n",
    "    # feature 4 parece ter 2 grupos de valores: altos e normais. Talvez a questao de lojas grande e normais?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# automatic feature generayion pras features 1-12 (1 - 18 se as features  13-18 forem necessarias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clustering (K-means with PCA / t-SNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA time series stuff (target variable time-series anlysis)\n",
    "# Scipy 2019 tutorial\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsitute Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treat Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection and engineering   \n",
    "    # - sabemos de antemao a \"cara\" dos resultados no comeco de ano pq a easonalidade é mt forte e a variancia eh pequena para meses\n",
    "    # - por isso seria bom dar uma forma dele copiar um pouco o ano passo, serve como uma proxy\n",
    "    # - feature categorica que vale: 'Janeiro'; 'Fevereiro', 'Marco', 'Outros'\n",
    "    \n",
    "    # feature binaria que vale 1 se as features 13 a 18 estao presentes e 0 caso contrario\n",
    "    \n",
    "    # feature trimestral, comeco do ano, meio, final\n",
    "    \n",
    "    # feature de numero de lojas na mesmo cod_ap \n",
    "    \n",
    "    # rotacionar latitude e longitude -> ajuda o modelo de arvore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode Categorical Values\n",
    " # mean encodings (pure or rounded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build lag_dataset (with lag variables/sliding window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build receita_diff (differentiated time series of target value)\n",
    "# plot it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lembrandoque vamos fazer a previsao do mes seguinte só, depois repetimos o mesmo processo para os proximos meses\n",
    "# train-test split \n",
    "# test set vai ser os ultimos 3 meses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local cross validation function\n",
    "     # lembrar de fazer sort by loja, pra fazer um stack das predictions [loja1: outubro2017 loja2: outubro2017 ...]\n",
    "     # pq na hora de fazer as previsoes vamos empacotar desse jeito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global cross validation function (next three months)\n",
    "    # prediction\n",
    "    # for i in range(1,3):\n",
    "    # faturamento_i+1 = append do train_i com prediction_i\n",
    "    # fazer tudo denovo\n",
    "        # train test split deixando ultimos 3 meses de fora\n",
    "        # treinar e cv modelos, treinar e cv ensemble, treinar modelos no dataset inteiro, treinar e cv ensemble no dataset inteiro\n",
    "        # conseguir prediction_i \n",
    "        # append prediction_i no prediction_months\n",
    "    # if cv=True \n",
    "        #call local cross validation and return cv \n",
    "    # else \n",
    "        #return prediction_months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline model 1\n",
    "\n",
    "# 0. Separar dataset para cada loja\n",
    "# 1. Fazer 2017 - 2016\n",
    "# 2. plotar \n",
    "# 3. fit and predict with ARIMA (diff = 1)\n",
    "# 5. somar valor obtido com 2016\n",
    "# 6. juntar as predictions\n",
    "# 4. cv ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline model 2\n",
    "\n",
    "# 0. Separar dataset para cada loja\n",
    "# 1. fit and predict with ARIMA (diff = 1 )\n",
    "# 2. somar com valor do mes passado\n",
    "# 3  juntar predtions\n",
    "# 4. cv ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost with lag dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train xgboost with lag dataset parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train other models\n",
    " # remember that with linear models we have to normalize variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# other models parameter tuning (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get parameters of ensemble, train models again on whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions wth global cv function (cv=False) for submission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
